{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re, sys\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the volumes used in the ACS project\n",
    "HATHIFILE = \"google_ids_1800-1850.txt.gz\"\n",
    "\n",
    "# corrected field names file. See also:\n",
    "# https://www.hathitrust.org/hathifiles_description\n",
    "HATHICOLS = \"hathifiles/hathi_field_list.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hathifile(ht_file, col_file):\n",
    "    \"\"\"\n",
    "    Return rows matching the query, as well as stubbytree paths for htids\n",
    "    \"\"\"\n",
    "\n",
    "    # Use iterative method to scale to full hathifiles\n",
    "    with open(col_file, \"r\") as fp:\n",
    "        col_names = fp.readline().strip('\\n').split('\\t')\n",
    "        num_cols = len(col_names)\n",
    "\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "    iter_csv = pd.read_csv(\n",
    "        ht_file, \n",
    "        sep='\\t', \n",
    "        header=None,\n",
    "        names=col_names,\n",
    "        engine='c',\n",
    "        # quicker if we can assert some types for the fields\n",
    "        dtype={\n",
    "            'htid': 'str',\n",
    "            'rights_date_used': 'object',\n",
    "            'pub_place': 'str', # sadly, this is just the partner lib\n",
    "            'imprint': 'str'\n",
    "        },\n",
    "        iterator=True,\n",
    "        chunksize=5000,\n",
    "        error_bad_lines=False)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i, chunk in enumerate(iter_csv):\n",
    "\n",
    "        # hard code query: use a basic regex with matching group\n",
    "        # find: \"Munroe, Francis\", \"Munroe and Francis\", \"Munroe & Francis\"\n",
    "        conditions = (chunk['imprint'].str.contains(\n",
    "            r\"\\bMunroe(?:,| and| &) Francis\\b\",\n",
    "            na=False,\n",
    "            flags=re.IGNORECASE)\n",
    "        )\n",
    "        # concatenate valid rows, idx doesn't matter\n",
    "        df = pd.concat([df, chunk[conditions]], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = search_hathifile(HATHIFILE, HATHICOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions from Hathi's feature datasets\n",
    "# https://github.com/htrc/htrc-feature-reader/blob/39010fd41c049f4f86b9c8ff4a44e000217093c2/htrc_features/utils.py\n",
    "\n",
    "def _id_encode(id):\n",
    "    '''\n",
    "    :param id: A Pairtree ID. If it's a Hathitrust ID, this is the part after the library\n",
    "        code; e.g. the part after the first period for vol.123/456.\n",
    "    :return: A sanitized id. e.g., 123/456 will return as 123=456 to avoid filesystem issues.\n",
    "    '''\n",
    "    return id.replace(\":\", \"+\").replace(\"/\", \"=\").replace(\".\", \",\")\n",
    "\n",
    "def _id_decode(id):\n",
    "    '''\n",
    "    :param id: A sanitized Pairtree ID.\n",
    "    :return: An original Pairtree ID.\n",
    "    '''\n",
    "    return id.replace(\"+\", \":\").replace(\"=\", \"/\").replace(\",\", \".\")\n",
    "\n",
    "def clean_htid(htid):\n",
    "    '''\n",
    "    :param htid: A HathiTrust ID of form lib.vol; e.g. mdp.1234\n",
    "    :return: A sanitized version of the HathiTrust ID, appropriate for filename use.\n",
    "    '''\n",
    "    libid, volid = htid.split('.', 1)\n",
    "    volid_clean = _id_encode(volid)\n",
    "    return '.'.join([libid, volid_clean])\n",
    "\n",
    "def id_to_stubbytree(htid, format = None, suffix = None, compression = None):\n",
    "    '''\n",
    "    Take an HTRC id and convert it to a 'stubbytree' location.\n",
    "    '''\n",
    "    libid, volid = htid.split('.', 1)\n",
    "    volid_clean = _id_encode(volid)\n",
    "\n",
    "    suffixes = [s for s in [format, compression] if s is not None]\n",
    "    filename = \".\".join([clean_htid(htid), *suffixes])\n",
    "    path = os.path.join(libid, volid_clean[::3], filename)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stubby_ids = [id_to_stubbytree(htid) for htid in df.htid.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stubby_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mdp\\\\31331\\\\mdp.39015038731918',\n",
       " 'mdp\\\\31197\\\\mdp.39015010791476',\n",
       " 'mdp\\\\31198\\\\mdp.39015010791484',\n",
       " 'mdp\\\\31199\\\\mdp.39015010791492',\n",
       " 'mdp\\\\31190\\\\mdp.39015010791500']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stubby_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_dir = Path(os.path.abspath('../_app-files/roi-vectors/vectors'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each volume, find associated .npy vectors within stubbytree directory\n",
    "munroe_francis = {}\n",
    "\n",
    "for stubby_id in stubby_ids:\n",
    "    vol_vectors = glob(os.path.join(rois_dir, stubby_id + \"*.npy\"))\n",
    "    if len(vol_vectors) != 0:\n",
    "        munroe_francis[stubby_id] = vol_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for vec_list in munroe_francis.values():\n",
    "    total += len(vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1477 vectors from 118 illustrated volumes (out of 360 total)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('munroe.csv', 'w') as fp:\n",
    "    for stubby_id in munroe_francis.keys():\n",
    "        fp.write(os.path.normpath(stubby_id))\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
