{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Visualize all illustrations for a given publisher\n",
    "\n",
    "In this case, the firm Munroe & Francis, active in Boston from c. 1800 to 1860."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Search Hathifile for publisher\n",
    "\n",
    "Hathifiles can be very big, so we iteratively search them for field (column) values matching a query. This can take some finesse, since publisher names are often very similar and the name of a firm can be written in slightly different ways (e.g. '&' vs. 'and')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random, re, sys\n",
    "from glob import glob\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the volumes used in the ACS project\n",
    "HATHIFILE = \"google_ids_1800-1850.txt.gz\"\n",
    "HATHICOLS = \"hathifiles/hathi_field_list.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hathifile(ht_file, col_file, search_col, search_expr):\n",
    "    \"\"\"\n",
    "    Given a hathifile and field names, return dataframe of rows\n",
    "    where search_col contains search_expr (a regex)\n",
    "    \"\"\"\n",
    "    # Use iterative method to scale to full hathifiles\n",
    "    with open(col_file, \"r\") as fp:\n",
    "        col_names = fp.readline().strip('\\n').split('\\t')\n",
    "        num_cols = len(col_names)\n",
    "\n",
    "    # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "    iter_csv = pd.read_csv(\n",
    "        ht_file, \n",
    "        sep='\\t', \n",
    "        header=None,\n",
    "        names=col_names,\n",
    "        engine='c',\n",
    "        # quicker if we can assert some types for the fields\n",
    "        dtype={\n",
    "            'htid': 'str',\n",
    "            'rights_date_used': 'object',\n",
    "            'pub_place': 'str', # sadly, this is just the partner lib\n",
    "            'imprint': 'str'\n",
    "        },\n",
    "        iterator=True,\n",
    "        chunksize=5000,\n",
    "        error_bad_lines=False)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i, chunk in enumerate(iter_csv):\n",
    "        condition = (chunk[search_col].str.contains(search_expr, na=False, flags=re.IGNORECASE))\n",
    "        \n",
    "        # hathifile idx has no relation to Neighbor tree: ignore\n",
    "        df = pd.concat([df, chunk[condition]], ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find publishers \"Munroe, Francis\", \"Munroe and Francis\", \"Munroe & Francis\" (with matching group)\n",
    "search_col = 'imprint'\n",
    "search_expr = r\"\\bMunroe(?:,| and| &) Francis\\b\"\n",
    "\n",
    "df = search_hathifile(HATHIFILE, HATHICOLS, search_col, search_expr)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imprint</th>\n",
       "      <th>rights_date_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Munroe and Francis [etc.]</td>\n",
       "      <td>1811.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     imprint rights_date_used\n",
       "0  Munroe and Francis [etc.]           1804.0\n",
       "1  Munroe and Francis [etc.]           1807.0\n",
       "2  Munroe and Francis [etc.]           1808.0\n",
       "3  Munroe and Francis [etc.]           1809.0\n",
       "4  Munroe and Francis [etc.]           1809.0\n",
       "5  Munroe and Francis [etc.]           1805.0\n",
       "6  Munroe and Francis [etc.]           1806.0\n",
       "7  Munroe and Francis [etc.]           1810.0\n",
       "8  Munroe and Francis [etc.]           1810.0\n",
       "9  Munroe and Francis [etc.]           1811.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a few results -- just the search field and the date published\n",
    "df[[search_col, 'rights_date_used']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find search result matches in illustration metadata\n",
    "\n",
    "We have a bunch of `htid`s from the Hathifile, but many of them will not contain any illustrations. To narrow down our set of results, we need to look up the `htid`s in our illustration metadata. This can be done with the main CSV file or with the vectors.tar file. Either way, the goal is to get a list of all image or vector files corresponding to specific regions of interest (illustrations) for the volumes returned in our search.\n",
    "\n",
    "If you want to work with the vectors in `vectors.tar`, you will want to convert to HTRCs stubbytree format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions from Hathi's feature datasets\n",
    "# https://github.com/htrc/htrc-feature-reader/blob/39010fd41c049f4f86b9c8ff4a44e000217093c2/htrc_features/utils.py\n",
    "def _id_encode(id):\n",
    "    '''\n",
    "    :param id: A Pairtree ID. If it's a Hathitrust ID, this is the part after the library\n",
    "        code; e.g. the part after the first period for vol.123/456.\n",
    "    :return: A sanitized id. e.g., 123/456 will return as 123=456 to avoid filesystem issues.\n",
    "    '''\n",
    "    return id.replace(\":\", \"+\").replace(\"/\", \"=\").replace(\".\", \",\")\n",
    "\n",
    "def _id_decode(id):\n",
    "    '''\n",
    "    :param id: A sanitized Pairtree ID.\n",
    "    :return: An original Pairtree ID.\n",
    "    '''\n",
    "    return id.replace(\"+\", \":\").replace(\"=\", \"/\").replace(\",\", \".\")\n",
    "\n",
    "def clean_htid(htid):\n",
    "    '''\n",
    "    :param htid: A HathiTrust ID of form lib.vol; e.g. mdp.1234\n",
    "    :return: A sanitized version of the HathiTrust ID, appropriate for filename use.\n",
    "    '''\n",
    "    libid, volid = htid.split('.', 1)\n",
    "    volid_clean = _id_encode(volid)\n",
    "    return '.'.join([libid, volid_clean])\n",
    "\n",
    "def id_to_stubbytree(htid, format = None, suffix = None, compression = None):\n",
    "    '''\n",
    "    Take an HTRC id and convert it to a 'stubbytree' location.\n",
    "    '''\n",
    "    libid, volid = htid.split('.', 1)\n",
    "    volid_clean = _id_encode(volid)\n",
    "\n",
    "    suffixes = [s for s in [format, compression] if s is not None]\n",
    "    filename = \".\".join([clean_htid(htid), *suffixes])\n",
    "    path = os.path.join(libid, volid_clean[::3], filename)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stubby_ids = [id_to_stubbytree(htid) for htid in df.htid.values]\n",
    "len(stubby_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B. this assumes the vectors.tar file has been extracted to this directory\n",
    "# You also need to be careful about filepath conventions; best to use os.path\n",
    "VEC_DIR = os.path.abspath(\"../_app-files/roi-vectors/vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each volume, find associated .npy vectors within stubbytree directory -- store in dictionary\n",
    "munroe_francis = {}\n",
    "for stubby_id in stubby_ids:\n",
    "    vol_path = os.path.join(VEC_DIR, stubby_id + \"*.npy\")\n",
    "    vol_vectors = glob(vol_path)\n",
    "    if len(vol_vectors) != 0:\n",
    "        munroe_francis[stubby_id] = vol_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: we can write out the matches to a text file (I did this to request the JPEG assets from HTRC)\n",
    "#with open('munroe.csv', 'w') as fp:\n",
    "#    for stubby_id in munroe_francis.keys():\n",
    "#        fp.write(os.path.normpath(stubby_id))\n",
    "#        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a (optional): Create Annoy index using project vectors\n",
    "\n",
    "You can experiment with building a smaller Annoy index with just these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified from: https://github.com/spotify/annoy\n",
    "f = 1000\n",
    "t = AnnoyIndex(f, 'angular')\n",
    "i = 0\n",
    "\n",
    "# Find all vectors per volume and index them from 0\n",
    "for k,v in munroe_francis.items():\n",
    "    for vec in v:\n",
    "        item = np.load(vec)\n",
    "        # transpose vector since it needs to be (1000,1) not (1,1000)\n",
    "        t.add_item(i, item.T)\n",
    "        i += 1\n",
    "\n",
    "# Try with 1000 trees\n",
    "t.build(1000)\n",
    "t.save('munroe-francis.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 614, 979, 905, 968, 177, 900, 955, 893, 677]\n"
     ]
    }
   ],
   "source": [
    "u = AnnoyIndex(f, 'angular')\n",
    "u.load('munroe-francis.ann')\n",
    "print(u.get_nns_by_item(0, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize images from search results\n",
    "\n",
    "Now that we have a reasonably sized subset matching our search query, we can visualize the ROIs belonging to those volumes.\n",
    "\n",
    "WARNING: we are still figuring out how to access the raw image data. I plan to write a fallback method that uses the Hathi Data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_DIR = \"..\\_app-files\\munroe-francis\\samplecrops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we know that each subdirectory is an htid, with JPEG crops inside it\n",
    "roi_jpegs = glob(ROI_DIR + '/*/*.jpg')\n",
    "len(roi_jpegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use pixplot: https://github.com/YaleDHLab/pix-plot\n",
    "# do a quick pip freeze of environment htrc (conda list as well)\n",
    "# remember to include metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
