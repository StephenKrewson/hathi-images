{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4dda3f2",
   "metadata": {},
   "source": [
    "## Download images from Google Cloud Storage\n",
    "\n",
    "The gsutil URIs for the dataset are of the form:\n",
    "\n",
    "```gs://hathitrust-full_1800-50/chi/000/chi.085041031_00000006_00.jpg```\n",
    "\n",
    "The bucket name is **hathitrust-full_1800-50** and the storage class is Nearline (multiple zones). The simplest way to land this data to a file is with gsutil, from the VM. But Python bindings are available as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c62d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c09a5242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=/home/stephen-krewson/project-hathi-images/global-matrix-242515-49432d870e22.json\n",
      "/home/stephen-krewson/project-hathi-images/global-matrix-242515-49432d870e22.json\r\n"
     ]
    }
   ],
   "source": [
    "# Check that GOOGLE_APPLICATION_CREDENTIALS is set. This is somewhat tricky from Jupyter:\n",
    "# Use a *full path* and the env command; !export has no effect\n",
    "%env GOOGLE_APPLICATION_CREDENTIALS=/home/stephen-krewson/project-hathi-images/global-matrix-242515-49432d870e22.json\n",
    "!echo $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b1b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(\"hathitrust-full_1800-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da81cc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Blob: hathitrust-full_1800-50, chi/000/chi.085041031_00000006_00.jpg, 1601825270933858>\n"
     ]
    }
   ],
   "source": [
    "blobs = storage_client.list_blobs(bucket)\n",
    "for blob in blobs:\n",
    "    print(blob)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44f26b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Google documentation\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_blob_name = \"storage-object-name\"\n",
    "    # destination_file_name = \"local/path/to/file\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Construct a client side representation of a blob.\n",
    "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
    "    # any content from Google Cloud Storage. As we don't need additional data,\n",
    "    # using `Bucket.blob` is preferred here.\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(\n",
    "        \"Blob {} downloaded to {}.\".format(\n",
    "            source_blob_name, destination_file_name\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80b1af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The intended location for the data. If within Git, remember to not version .jpg files.\n",
    "# Make sure the data is being backed up on my 4TB disk; so best to keep it on C:\\\n",
    "METADATA_FILE = \"../metadata/pixplot_peter-parley.csv\"\n",
    "OUTPUT_DIR = \"~/datasets/peter-parley/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c66c6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f4e3ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    mdp/31656/mdp.39015063752268_00000015_00.jpg\n",
       "1    mdp/31656/mdp.39015063752268_00000048_01.jpg\n",
       "2    mdp/31656/mdp.39015063752268_00000036_00.jpg\n",
       "3    mdp/31656/mdp.39015063752268_00000060_00.jpg\n",
       "4    mdp/31656/mdp.39015063752268_00000072_01.jpg\n",
       "Name: filename, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filename'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a694eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSE THE QUESTION BEFORE RUNNING THE JOB! Consider adding \"geography\" to Peter Parley query?\n",
    "# How many more volumes would this add?\n",
    "# PixPlot 1: Educational publishers (Carter Hendee, Munroe Francis, etc.). Cf. Goodrich's output and memoirs.\n",
    "# PixPlot 2: Geography books and Peter Parley texts. Searching title for geography OR peter parley. To avoid dedup step.\n",
    "# https://cloud.google.com/storage/docs/downloading-objects#storage-download-object-python\n",
    "# https://cloud.google.com/storage/docs/reference/libraries#command-line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
